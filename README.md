Comparative analysis of 4 LLM models(GPT-4.0 Turbo,BLIP-2,Claude Sonnet 4, ClipCap) for the task of Image Captioning. 


BLIP-2 source : https://huggingface.co/Salesforce/blip2-opt-2.7b

ClipCap repo:https://github.com/rmokady/CLIP_prefix_caption

Dataset : https://www.kaggle.com/datasets/adityajn105/flickr30k

Content: Diverse visual scenarios with multiple reference captions
Evaluation: 5 human-annotated captions per image
